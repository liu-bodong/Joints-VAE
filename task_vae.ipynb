{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef910088",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import math\n",
    "import pandas as pd\n",
    "# import ikpy.chain\n",
    "# import ikpy.utils.plot as plot_utils\n",
    "import itertools\n",
    "import csv\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import tqdm\n",
    "# from chamferdist import ChamferDistance  # https://github.com/krrish94/chamferdist?tab=readme-ov-file\n",
    "# import ChamferDistancePytorch.chamfer3D.dist_chamfer_3D\n",
    "import kinematics\n",
    "import utils\n",
    "import network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62003037",
   "metadata": {},
   "outputs": [],
   "source": [
    "N_USERS = 76\n",
    "M_POSES = 4096  # Number of points for each point cloud\n",
    "K_TASK_POINTS = 256   # Number of points to generate in task-space\n",
    "LATENT_DIM = 128\n",
    "LEARNING_RATE = 1e-5\n",
    "EPOCHS = 1000\n",
    "BATCH_SIZE = 128\n",
    "BETA_KL = 0.001 # Weight for KL loss\n",
    "TRAIN_SIZE   = math.floor(0.8 * N_USERS)\n",
    "VAL_SIZE     = N_USERS - TRAIN_SIZE\n",
    "\n",
    "# Setup device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "raw_data = np.loadtxt(\"task_sp_points.csv\", delimiter=',', skiprows=1)\n",
    "raw_data = torch.tensor(raw_data[:, 1:], dtype=torch.float32)\n",
    "raw_data = raw_data.view(N_USERS, -1, 3)  # [N_USERS, K_TASK_POINTS, 3]\n",
    "raw_data.shape\n",
    "\n",
    "train_dataset = raw_data[0:TRAIN_SIZE].to(device)\n",
    "val_dataset   = raw_data[TRAIN_SIZE:N_USERS].to(device)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "val_loader   = torch.utils.data.DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "\n",
    "model = network.fROM_VAE_task(input_dim=3, latent_dim=128, num_task_points=256).to(device)\n",
    "model = model.to(device)\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
    "chamfer_loss = utils.chamfer_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "906c2efb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get one batch of data and see shape\n",
    "data_batch = train_dataset[0:BATCH_SIZE]\n",
    "data_batch.shape  # [BATCH_SIZE, K_TASK_POINTS, 3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42ee7b93",
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 3000\n",
    "LEARNING_RATE = 1e-5\n",
    "KL_WEIGHT = 0.0001\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    model.train()\n",
    "    total_loss_epoch = 0\n",
    "    chamfer_loss_epoch = 0\n",
    "    kl_loss_epoch = 0\n",
    "    \n",
    "    for pc in tqdm.tqdm(train_loader, desc=f\"Epoch {epoch+1}/{EPOCHS} - Training\", unit=\"batch\", leave=False):\n",
    "        pc = pc.to(device) # [B, M, 3]\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        pc_recon, mu, logvar = model(pc)\n",
    "        \n",
    "        loss_chamfer = chamfer_loss(pc, pc_recon)\n",
    "        loss_kld = -0.5 * torch.mean(1 + logvar - mu.pow(2) - logvar.exp())\n",
    "        loss = loss_chamfer + KL_WEIGHT * loss_kld\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        total_loss_epoch += loss.item()\n",
    "        chamfer_loss_epoch += loss_chamfer.item()\n",
    "        kl_loss_epoch += loss_kld.item()\n",
    "        \n",
    "    if (epoch + 1) % 300 == 0:\n",
    "        avg_train = total_loss_epoch / len(train_loader)\n",
    "        avg_chamfer = chamfer_loss_epoch / len(train_loader)\n",
    "        avg_kl = kl_loss_epoch / len(train_loader)\n",
    "        print(f\"Epoch [{epoch+1}/{EPOCHS}] Train Loss: {avg_train:.4f}, Chamfer Loss: {avg_chamfer:.4f}, KL Loss: {avg_kl:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2add7020",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model.eval()\n",
    "errors = 0.0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for pc in tqdm.tqdm(val_loader, desc=\"Validation\", unit=\"batch\"):\n",
    "        pc = pc.to(device)  # [B, M, 3]\n",
    "        \n",
    "        pc_recon, mu, logvar = model(pc)\n",
    "        \n",
    "        loss_chamfer = chamfer_loss(pc, pc_recon)\n",
    "        loss_kld = -0.5 * torch.mean(1 + logvar - mu.pow(2) - logvar.exp())\n",
    "        loss = loss_chamfer + KL_WEIGHT * loss_kld\n",
    "        \n",
    "        errors += loss.item() * pc.size(0)\n",
    "avg_error = errors / len(val_loader.dataset)\n",
    "print(f\"Validation Loss: {avg_error:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e856c181",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), 'PC_VAE_76_4096.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9787a9e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize\n",
    "with torch.no_grad():\n",
    "    x = train_dataset[5, :, :].to(device) # [B, 4]\n",
    "    \n",
    "    recon_x, _, _ = model(x.view(-1, K_TASK_POINTS, 3))\n",
    "    \n",
    "    fig = plt.figure(figsize=(10, 5))\n",
    "    ax1 = fig.add_subplot(121, projection='3d')\n",
    "    ax1.scatter(x[:, 0].cpu(), x[:, 1].cpu(), x[:, 2].cpu(), c='b', s=1)\n",
    "    ax1.set_title('Original Point Cloud')\n",
    "    ax2 = fig.add_subplot(122, projection='3d')\n",
    "    ax2.scatter(recon_x[0, :, 0].cpu(), recon_x[0, :, 1].cpu(), recon_x[0, :, 2].cpu(), c='r', s=1)\n",
    "    ax2.set_title('Reconstructed Point Cloud')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f08b7f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sanity check, interpolate\n",
    "with torch.no_grad():\n",
    "    pc1 = train_dataset[7:8, :, :]  # [1, K_TASK_POINTS, 3]\n",
    "    pc2 = train_dataset[4:5, :, :]  # [1, K_TASK_POINTS, 3]\n",
    "\n",
    "    z1, _ = model.encoder(pc1)\n",
    "    z2, _ = model.encoder(pc2)\n",
    "\n",
    "    z_interp = torch.linspace(0, 1, steps=10).unsqueeze(1).to(device) * z2 + (1 - torch.linspace(0, 1, steps=10).unsqueeze(1).to(device)) * z1\n",
    "    pc_interp = model.decoder(z_interp)  # [10, K_TASK_POINTS, 3]\n",
    "    \n",
    "    # pc1_prime = model.decoder(z1)\n",
    "    # pc2_prime = model.decoder(z2)\n",
    "    # pc_interp = torch.cat([pc1_prime, pc2_prime], dim=0)\n",
    "\n",
    "    pc_interp = pc_interp.cpu().numpy()\n",
    "    fig = plt.figure(figsize=(25, 5))\n",
    "    for i in range(pc_interp.shape[0]):\n",
    "        ax = fig.add_subplot(1, pc_interp.shape[0], i+1, projection='3d')\n",
    "        ax.scatter(pc_interp[i, :, 0], pc_interp[i, :, 1], pc_interp[i, :, 2], s=1)\n",
    "        ax.set_title(f\"Interp {i+1}\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb4401d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize dataset\n",
    "fig = plt.figure(figsize=(20, 20))\n",
    "for i in range(25):\n",
    "    ax = fig.add_subplot(5, 5, i+1, projection='3d')\n",
    "    ax.scatter(train_dataset[i:i+1, :, 0].cpu(), train_dataset[i:i+1, :, 1].cpu(), train_dataset[i:i+1, :, 2].cpu(), s=1)\n",
    "    ax.set_title(f\"Sample {i+1}\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fcd70cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "fig = plt.figure(figsize=(20, 20))\n",
    "for i in range(25):\n",
    "    ax = fig.add_subplot(5, 5, i+1,)\n",
    "    ax.scatter(train_dataset[i:i+1, :, 0].cpu(), train_dataset[i:i+1, :, 1].cpu(), s=1)\n",
    "    ax.set_title(f\"Sample {i+1}\")\n",
    "plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "620ec22c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Make sure raw_data is a numpy array on the CPU\n",
    "# If raw_data is still a torch tensor, convert it:\n",
    "# data_to_plot = raw_data.cpu().numpy()\n",
    "data_to_plot = raw_data.numpy() # If it's a CPU tensor\n",
    "\n",
    "# --- Plot a Single User's Point Cloud ---\n",
    "pc = data_to_plot[0]  # Get the first user's data [256, 3]\n",
    "\n",
    "# Extract x, y, z coordinates\n",
    "x = pc[:, 0]\n",
    "y = pc[:, 1]\n",
    "z = pc[:, 2]\n",
    "\n",
    "# Create the 3D plot\n",
    "fig = plt.figure(figsize=(10, 8))\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "ax.scatter(x, y, z, marker='.', s=10) # 's' is the marker size\n",
    "\n",
    "ax.set_xlabel('X Coordinate')\n",
    "ax.set_ylabel('Y Coordinate')\n",
    "ax.set_zlabel('Z Coordinate')\n",
    "ax.set_title('3D Scatter Plot of Task-Space Points (User 0)')\n",
    "plt.show()\n",
    "\n",
    "# --- (Optional) Plot Multiple Users ---\n",
    "# This shows if all users share the same surface\n",
    "fig = plt.figure(figsize=(10, 8))\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "colors = ['r', 'g', 'b', 'c', 'm', 'y']\n",
    "for i in range(min(len(data_to_plot), 6)): # Plot up to 6 users\n",
    "    pc = data_to_plot[i]\n",
    "    ax.scatter(pc[:, 0], pc[:, 1], pc[:, 2], marker='.', s=10, c=colors[i], label=f'User {i}')\n",
    "\n",
    "ax.set_xlabel('X Coordinate')\n",
    "ax.set_ylabel('Y Coordinate')\n",
    "ax.set_zlabel('Z Coordinate')\n",
    "ax.set_title('Overlay of Multiple User Point Clouds')\n",
    "ax.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47c85202",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acadf4a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# source_cloud = raw_data[0:5].to(device) \n",
    "# target_cloud = raw_data[0:5].to(device)\n",
    "\n",
    "# loss = utils.chamfer_loss(source_cloud, target_cloud)\n",
    "\n",
    "# print(f\"Chamfer Loss (Pure PyTorch): {loss.item()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69185989",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(f\"Python Version: {os.sys.version}\")\n",
    "# print(f\"PyTorch Version: {torch.__version__}\")\n",
    "# print(f\"CUDA Version (PyTorch was built with): {torch.version.cuda}\")\n",
    "# print(f\"Is CUDA available? {torch.cuda.is_available()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd1342a7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
