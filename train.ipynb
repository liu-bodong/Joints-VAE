{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b5c9014",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import math\n",
    "import pandas as pd\n",
    "import tqdm\n",
    "\n",
    "import network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b3f5ab1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "db17da1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "\n",
    "N_USERS = 81\n",
    "M_POSES = 1024  # Number of points to sample joint-space\n",
    "K_TASK_POINTS = 256   # Number of points to generate in task-space\n",
    "LATENT_DIM = 128\n",
    "LEARNING_RATE = 1e-4\n",
    "EPOCHS = 5000\n",
    "BATCH_SIZE = 4096\n",
    "BETA_KL = 0.001 # Weight for KL loss\n",
    "\n",
    "\n",
    "# Setup device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "joint_limits = np.loadtxt(\"joint_limits.csv\", delimiter=',', skiprows=1)\n",
    "joint_limits = torch.tensor(joint_limits, dtype=torch.float32)\n",
    "\n",
    "joint_configs = np.loadtxt(\"all_users_fROM_data.csv\", delimiter=',', skiprows=1)\n",
    "joint_configs = torch.tensor(joint_configs, dtype=torch.float32)\n",
    "\n",
    "DATASET_SIZE = N_USERS\n",
    "TRAIN_SIZE   = math.floor(0.8 * DATASET_SIZE)\n",
    "VAL_SIZE     = DATASET_SIZE - TRAIN_SIZE\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "a925c6a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([81, 8])\n",
      "torch.Size([81, 1024, 4])\n"
     ]
    }
   ],
   "source": [
    "joint_configs = joint_configs.view(-1, M_POSES, 5)  # [N, M, 4]\n",
    "joint_configs = joint_configs[:, :, 1:]  # Remove user ID column\n",
    "\n",
    "joint_limits = joint_limits[:, 1:]  # Remove user ID column\n",
    "\n",
    "print(joint_limits.shape)\n",
    "print(joint_configs.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "a83b737f",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = TensorDataset(joint_configs, joint_limits)\n",
    "\n",
    "train_dataset, val_dataset = torch.utils.data.random_split(dataset, [TRAIN_SIZE, VAL_SIZE])\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "val_loader   = DataLoader(val_dataset,   batch_size=BATCH_SIZE, shuffle=False)\n",
    "\n",
    "model = network.fROM_VAE_joints(joint_dim=4, latent_dim=LATENT_DIM, global_feat_dim=1024, output_limits_dim=8).to(device)\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
    "recon_loss_fn = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8253d80",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [500/5000], Loss: 7.9976, Recon Loss (MSE): 7.5825, KL Loss: 415.1252\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1000/5000], Loss: 4.4038, Recon Loss (MSE): 4.0747, KL Loss: 329.0664\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1500/5000], Loss: 2.3285, Recon Loss (MSE): 2.0382, KL Loss: 290.2384\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2000/5000], Loss: 0.6849, Recon Loss (MSE): 0.4176, KL Loss: 267.2554\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2500/5000], Loss: 0.4121, Recon Loss (MSE): 0.1655, KL Loss: 246.5277\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3000/5000], Loss: 0.3271, Recon Loss (MSE): 0.0905, KL Loss: 236.6620\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3500/5000], Loss: 0.3254, Recon Loss (MSE): 0.1004, KL Loss: 224.9945\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4000/5000], Loss: 0.3099, Recon Loss (MSE): 0.0889, KL Loss: 221.0229\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4500/5000], Loss: 0.2829, Recon Loss (MSE): 0.0689, KL Loss: 214.0048\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                      \r"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "unsupported format string passed to numpy.ndarray.__format__",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[72], line 27\u001b[0m\n\u001b[0;32m     24\u001b[0m loss \u001b[38;5;241m=\u001b[39m (recon_loss \u001b[38;5;241m/\u001b[39m BATCH_SIZE) \u001b[38;5;241m+\u001b[39m (BETA_KL \u001b[38;5;241m*\u001b[39m kl_loss \u001b[38;5;241m/\u001b[39m BATCH_SIZE)\n\u001b[0;32m     26\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m epoch \u001b[38;5;241m==\u001b[39m EPOCHS \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m---> 27\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00my_recon[:\u001b[38;5;241m3\u001b[39m]\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mnumpy()\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.2f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     28\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00my[:\u001b[38;5;241m3\u001b[39m]\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mnumpy()\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.2f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     29\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrecon_loss: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrecon_loss\u001b[38;5;241m.\u001b[39mitem()\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, kl_loss: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkl_loss\u001b[38;5;241m.\u001b[39mitem()\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, total_loss: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mloss\u001b[38;5;241m.\u001b[39mitem()\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mTypeError\u001b[0m: unsupported format string passed to numpy.ndarray.__format__"
     ]
    }
   ],
   "source": [
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    model.train()\n",
    "    total_loss_epoch = 0\n",
    "    total_recon_loss_epoch = 0\n",
    "    total_kl_loss_epoch = 0\n",
    "    \n",
    "    for x, y in tqdm.tqdm(train_loader, desc=f\"Epoch {epoch+1}/{EPOCHS}\", leave=False):\n",
    "        print(x.shape, y.shape)\n",
    "        x = x.to(device)  # [B, M, 4]\n",
    "        y = y.to(device)  # [B, 8]\n",
    "        \n",
    "        # Forward pass\n",
    "        y_recon, mu, logvar = model(x) # [B, 8], [B, D_z], [B, D_z]\n",
    "        \n",
    "        # Loss\n",
    "        # Reconstruction Loss (MSE on the 8 limit values)\n",
    "        recon_loss = recon_loss_fn(y_recon, y)\n",
    "        \n",
    "        # KL\n",
    "        kl_loss = -0.5 * torch.sum(1 + logvar - mu.pow(2) - logvar.exp())\n",
    "        \n",
    "        loss = (recon_loss / BATCH_SIZE) + (BETA_KL * kl_loss / BATCH_SIZE)\n",
    "        \n",
    "        if epoch == EPOCHS - 1:\n",
    "            print(f\"{y_recon[:3].detach().cpu().numpy()}\")\n",
    "            print(f\"{y[:3].detach().cpu().numpy()}\")\n",
    "            print(f\"recon_loss: {recon_loss.item():.4f}, kl_loss: {kl_loss.item():.4f}, total_loss: {loss.item():.4f}\")\n",
    "            \n",
    "        \n",
    "        # Backward pass\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        total_loss_epoch += loss.item() * BATCH_SIZE\n",
    "        total_recon_loss_epoch += recon_loss.item()\n",
    "        total_kl_loss_epoch += kl_loss.item()\n",
    "\n",
    "    # Print epoch stats\n",
    "    avg_loss = total_loss_epoch / TRAIN_SIZE  # 2560\n",
    "    avg_recon = total_recon_loss_epoch / TRAIN_SIZE\n",
    "    avg_kl = total_kl_loss_epoch / TRAIN_SIZE\n",
    "    \n",
    "    if (epoch + 1) % 500 == 0:\n",
    "        print(f\"Epoch [{epoch+1}/{EPOCHS}], Loss: {avg_loss:.4f}, \"\n",
    "              f\"Recon Loss (MSE): {avg_recon:.4f}, KL Loss: {avg_kl:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ae8bdf2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-1.0767770e+02  2.9013262e+01 -4.7637493e+01  1.0009959e+02\n",
      "  -5.3098145e+01  5.3158630e+01 -2.8632693e-02  1.4951682e+02]\n",
      " [-8.2999916e+01  2.2308062e+01 -8.0873634e+01  1.6301045e+02\n",
      "  -4.1522953e+01  4.1347366e+01 -1.4251691e-01  3.5909512e+01]\n",
      " [-7.9858574e+01  1.9954647e+01 -5.4268040e+01  1.0796791e+02\n",
      "  -9.8724815e+01  9.8368866e+01 -1.2270026e-02  9.0486626e+01]]\n",
      "[[-110.   30.  -50.  100.  -60.   60.    0.  150.]\n",
      " [ -80.   20.  -90.  180.  -30.   30.    0.   40.]\n",
      " [ -80.   20.  -50.  100.  -90.   90.    0.   90.]]\n",
      "Validation Reconstruction Error (MSE): 2.1194\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "error = 0.0\n",
    "for x, y in val_loader:\n",
    "    with torch.no_grad():\n",
    "        x = x.to(device)  # [B, M, 4]\n",
    "        y = y.to(device)  # [B, 8]\n",
    "        y_recon, mu, logvar = model(x) # [B, 8], [B, D_z], [B, D_z]\n",
    "        \n",
    "        error += recon_loss_fn(y_recon, y).item()\n",
    "        \n",
    "        print(f\"{y_recon[:3].detach().cpu().numpy()}\")\n",
    "        print(f\"{y[:3].detach().cpu().numpy()}\")\n",
    "        \n",
    "avg_error = error / VAL_SIZE\n",
    "print(f\"Validation Reconstruction Error (MSE): {avg_error:.4f}\")\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "497f4316",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dc0e849",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "a2aec54c",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "mat1 and mat2 shapes cannot be multiplied (1x1 and 1024x128)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[65], line 8\u001b[0m\n\u001b[0;32m      5\u001b[0m x_input \u001b[38;5;241m=\u001b[39m x_test_sample[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m0\u001b[39m)\u001b[38;5;241m.\u001b[39mto(device) \u001b[38;5;66;03m# [1, M, 4]\u001b[39;00m\n\u001b[0;32m      6\u001b[0m y_truth \u001b[38;5;241m=\u001b[39m y_test_sample[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mnumpy()          \u001b[38;5;66;03m# [8]\u001b[39;00m\n\u001b[1;32m----> 8\u001b[0m y_pred, _, _ \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_input\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;66;03m# [1, 8]\u001b[39;00m\n\u001b[0;32m      9\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m y_pred\u001b[38;5;241m.\u001b[39msqueeze()\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mnumpy()\n\u001b[0;32m     11\u001b[0m y_truth_deg \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mrad2deg(y_truth)\n",
      "File \u001b[1;32md:\\anaconda3\\envs\\nn\\lib\\site-packages\\torch\\nn\\modules\\module.py:1751\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1749\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1751\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32md:\\anaconda3\\envs\\nn\\lib\\site-packages\\torch\\nn\\modules\\module.py:1762\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1757\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1758\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1759\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1760\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1761\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1762\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1764\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1765\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32me:\\dev\\research\\Joints-VAE\\network.py:124\u001b[0m, in \u001b[0;36mfROM_VAE_joints.forward\u001b[1;34m(self, joint_cloud)\u001b[0m\n\u001b[0;32m    122\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, joint_cloud):\n\u001b[0;32m    123\u001b[0m     \u001b[38;5;66;03m# joint_cloud shape: [B, M, 4]\u001b[39;00m\n\u001b[1;32m--> 124\u001b[0m     mu, logvar \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoder\u001b[49m\u001b[43m(\u001b[49m\u001b[43mjoint_cloud\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    125\u001b[0m     z \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreparameterize(mu, logvar)\n\u001b[0;32m    126\u001b[0m     limits_recon \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdecoder(z) \u001b[38;5;66;03m# [B, 8]\u001b[39;00m\n",
      "File \u001b[1;32md:\\anaconda3\\envs\\nn\\lib\\site-packages\\torch\\nn\\modules\\module.py:1751\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1749\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1751\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32md:\\anaconda3\\envs\\nn\\lib\\site-packages\\torch\\nn\\modules\\module.py:1762\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1757\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1758\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1759\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1760\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1761\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1762\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1764\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1765\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32me:\\dev\\research\\Joints-VAE\\network.py:29\u001b[0m, in \u001b[0;36mPointNetEncoder.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     27\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfeat_mlp(x)       \u001b[38;5;66;03m# [B, M, 1024]\u001b[39;00m\n\u001b[0;32m     28\u001b[0m x \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mmax(x, \u001b[38;5;241m1\u001b[39m)[\u001b[38;5;241m0\u001b[39m]     \u001b[38;5;66;03m# [B, 1024] (Global max pooling)\u001b[39;00m\n\u001b[1;32m---> 29\u001b[0m mu \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfc_mu\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m         \u001b[38;5;66;03m# [B, D_z]\u001b[39;00m\n\u001b[0;32m     30\u001b[0m logvar \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfc_logvar(x) \u001b[38;5;66;03m# [B, D_z]\u001b[39;00m\n\u001b[0;32m     31\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m mu, logvar\n",
      "File \u001b[1;32md:\\anaconda3\\envs\\nn\\lib\\site-packages\\torch\\nn\\modules\\module.py:1751\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1749\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1751\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32md:\\anaconda3\\envs\\nn\\lib\\site-packages\\torch\\nn\\modules\\module.py:1762\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1757\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1758\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1759\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1760\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1761\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1762\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1764\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1765\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32md:\\anaconda3\\envs\\nn\\lib\\site-packages\\torch\\nn\\modules\\linear.py:125\u001b[0m, in \u001b[0;36mLinear.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    124\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m--> 125\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: mat1 and mat2 shapes cannot be multiplied (1x1 and 1024x128)"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    x_test_sample, y_test_sample = next(iter(val_dataset)) # [B, M, 4], [B, 8]\n",
    "    \n",
    "    x_input = x_test_sample[0].unsqueeze(0).to(device) # [1, M, 4]\n",
    "    y_truth = y_test_sample[0].cpu().numpy()          # [8]\n",
    "    \n",
    "    y_pred, _, _ = model(x_input) # [1, 8]\n",
    "    y_pred = y_pred.squeeze().cpu().numpy()\n",
    "    \n",
    "    y_truth_deg = np.rad2deg(y_truth)\n",
    "    y_pred_deg = np.rad2deg(y_pred)\n",
    "\n",
    "    y_truth_deg[0:4] = -1 * (y_truth_deg[0:4] % 360)\n",
    "    y_truth_deg[4:] = y_truth_deg[4:] % 360\n",
    "    y_pred_deg[0:4] = -1 * (y_pred_deg[0:4] % 360)\n",
    "    y_pred_deg[4:] = y_pred_deg[4:] % 360\n",
    "\n",
    "    \n",
    "    # print(\"Example from Test Set (in deg):\")\n",
    "    # print(\"---------------------------------\")\n",
    "    # print(f\"JOINT         | TRUTH (min/max)  | PRED (min/max)\")\n",
    "    # print(f\"Shoulder Abd  | {y_truth_deg[0]:.1f} / {y_truth_deg[4]:.1f}   | {y_pred_deg[0]:.1f} / {y_pred_deg[4]:.1f}\")\n",
    "    # print(f\"Shoulder Flex | {y_truth_deg[1]:.1f} / {y_truth_deg[5]:.1f}  | {y_pred_deg[1]:.1f} / {y_pred_deg[5]:.1f}\")\n",
    "    # print(f\"Shoulder Rot  | {y_truth_deg[2]:.1f} / {y_truth_deg[6]:.1f}   | {y_pred_deg[2]:.1f} / {y_pred_deg[6]:.1f}\")\n",
    "    # print(f\"Elbow Flex    | {y_truth_deg[3]:.1f} / {y_truth_deg[7]:.1f}    | {y_pred_deg[3]:.1f} / {y_pred_deg[7]:.1f}\")\n",
    "    \n",
    "    print(\"Example from Test Set (in deg):\")\n",
    "    print(\"---------------------------------\")\n",
    "    print(f\"JOINT         | TRUTH (min/max)  | PRED (min/max)\")\n",
    "    print(f\"Shoulder Abd  | {y_truth[0]:.1f} / {y_truth[4]:.1f}   | {y_pred[0]:.1f} / {y_pred[4]:.1f}\")\n",
    "    print(f\"Shoulder Flex | {y_truth[1]:.1f} / {y_truth[5]:.1f}   | {y_pred[1]:.1f} / {y_pred[5]:.1f}\")\n",
    "    print(f\"Shoulder Rot  | {y_truth[2]:.1f} / {y_truth[6]:.1f}   | {y_pred[2]:.1f} / {y_pred[6]:.1f}\")\n",
    "    print(f\"Elbow Flex    | {y_truth[3]:.1f} / {y_truth[7]:.1f}   | {y_pred[3]:.1f} / {y_pred[7]:.1f}\")\n",
    "\n",
    "    mse_rad = np.mean((y_truth - y_pred)**2) # MSE in rad\n",
    "    print(f\"\\nExample's MSE (deg^2): {mse_rad:.6f}\")\n",
    "    # mse_deg = np.mean((y_truth_deg - y_pred_deg)**2) # MSE in deg=\n",
    "    # print(f\"Example's MSE (deg^2): {mse_deg:.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ee3c251",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e0a942b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
